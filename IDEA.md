# THE LOGICAL FLOW OF METRIC OPTIMIZATION

```mermaid
flowchart TD

A[PCA / Preprocessing] --> B[EDA]

B --> C[Define target metric<br>Stratified split]
C --> D((Train))
C --> E((Test))

%% SVM Branch
D --> S1[Baseline SVM<br>High precision, low recall]
S1 --> S2[Hypothesis: imbalance â†’ bad margin]
S2 --> S3[Tune class_weight]
S3 --> S4[Tune threshold<br>â†’ Improve recall]
S4 --> SOK[âœ” Linear branch validated]

%% RF Branch
D --> R1[Random Forest]
R1 --> R2[Hypothesis: model biased by imbalance]
R2 --> R3[Apply SMOTE]
R3 --> R4[Apply Borderline-SMOTE]
R4 --> R5[Tune sampling_strategy]
R5 --> ROK[âœ” Tree-based branch validated]

%% AE Branch
D --> A1[Autoencoder<br>Latent + Recon error]
A1 --> A2[Hypothesis: non-linear manifold â†’ better anomaly signal]
A2 --> A3[Tune sampling_strategy or thresholds]
A3 --> AOK[âœ” Representation branch validated]

%% Final
E --> F[Apply full pipeline<br>Estimate production performance]
F --> END[âœ” Done]

```
# TABLE OF MODEL OPTIMIZATION
| Step | Change | Result |Problem |Explain | Decision |Expect|
|-|-|-|-|-|-|-|
| 1 | Baseline vá»›i SVM|...|Precision á»Ÿ má»©c cao, trong khi recall chá»‰ á»Ÿ má»©c tháº¥p, mÃ´ hÃ¬nh khÃ´ng tá»‘t cho viá»‡c báº¯t cÃ¡c case fraud|Do sá»± imbalance cá»§a dá»¯ liá»‡u, báº£n cháº¥t cá»§a SVM optimize vá»›i loss giá»¯a 2 lá»›p báº±ng nhau, do imbalance, decision boundary sáº½ bá»‹ kÃ©o sang phÃ¡i minority, vÃ¬ mÃ´ hÃ¬nh Ä‘ang hÆ°á»›ng giáº£m loss cá»§a majority|Thay Ä‘á»•i **class_weight** Ä‘á»ƒ penalize minority classification Ä‘á»ƒ dá»‹ch decision boundary|Recall cÃ³ thá»ƒ sáº½ tÄƒng náº¿u tá»“n táº¡i cÃ¡c fraud case náº±m gáº§n decision boundary nhÆ°ng bá»‹ miss do imbalance, precision cÃ³ thá»ƒ giáº£m trong trÆ°á»ng há»£p decision boundary bá»‹ Ä‘áº©y sang majority, gÃ¢y tÄƒng FP|
|2|Thay Ä‘á»•i hyper-parameter **class_weight**|...| Precision giáº£m má»™t cÃ¡ch Ä‘á»™t ngá»™t, recall tÄƒng á»•n | Khi thay Ä‘á»•i giÃ¡ trá»‹ class_weight, decision boundary bá»‹ dá»‹ch sang hÆ°á»›ng majority, táº¡o ra sá»± má»Ÿ rá»™ng bÃªn phÃ­a minority, Ä‘iá»u nÃ y cho phÃ©p model báº¯t Ä‘Æ°á»£c cÃ¡c fraud case, tuy nhiÃªn bá»Ÿi vÃ¬ cÃ¡c case bÃ¬nh thÆ°á»ng quÃ¡ nhiá»u gáº§n margin, FP tÄƒng cá»±c máº¡nh, dáº«n Ä‘áº¿n precision giáº£m Ä‘au Ä‘á»›n, giÃ¡ trá»‹ balanced lÃ m cho model quyáº¿t Ä‘á»‹nh pháº£i báº¯t fraud báº±ng má»i cÃ¡ch Ä‘á»ƒ giáº£m loss, tháº­m chÃ­ lÃ  hy sinh háº±ng trÄƒm case bÃ¬nh thÆ°á»ng. Do Ä‘Ã³ cho dÃ¹ cÃ³ tá»“n táº¡i nhá»¯ng case bá»‹ miss, gáº§n boundary, SVM sáº½ má»Ÿ rá»™ng boundary má»™t cÃ¡ch quÃ¡ trá»›n Ä‘á»ƒ báº¯t cÃ¡c fraud, máº·c dÃ¹ chÃºng cÃ³ thá»ƒ náº±m sau bÃªn trong majority class|Tune class_weight má»™t cÃ¡ch cáº©n tháº­n hÆ¡n, khÃ´ng nÃªn sá»­ dá»¥ng giÃ¡ trá»‹ balanced|Sáº½ cÃ³ trade-off giá»¯a precision vÃ  recall, nhÆ°ng ta sáº½ tÃ¬m má»™t **sweet pot** Ä‘á»ƒ mÃ´ hÃ¬nh cÃ³ thá»ƒ tÄƒng Ä‘Æ°á»£c recall, nhÆ°ng váº«n giá»¯ Ä‘Æ°á»£c má»©c precision á»•n
| 3 | Tune giÃ¡ trá»‹ **class_weight** trÃªn cÃ¡c khoáº£ng | ... | Precision giáº£m Ä‘á»u khi weight tÄƒng. Recall tÄƒng nhanh khi weight tá»« 1-10, sau Ä‘Ã³ tÄƒng cháº­m.FP tÄƒng máº¡nh khi weight quÃ¡ cao. | NhÃ³m fraud gáº§n biÃªn dá»… Ä‘Æ°á»£c phÃ¢n tÃ¡ch tuyáº¿n tÃ­nh, nÃªn recall tÄƒng nhanh á»Ÿ giai Ä‘oáº¡n Ä‘áº§u. NhÃ³m fraud náº±m sÃ¢u trong majority, cáº§n Ä‘áº©y ranh giá»›i máº¡nh â†’ FP tÄƒng. Linear SVM tuyáº¿n tÃ­nh khÃ´ng thá»ƒ phÃ¢n tÃ¡ch tá»‘t cÃ¡c cáº¥u trÃºc phi tuyáº¿n. | - XÃ¡c Ä‘á»‹nh má»©c weight cÃ¢n báº±ng giá»¯a recall vÃ  precision. Tiáº¿p tá»¥c thá»­ threshold tuning| Cáº£i thiá»‡n F2-score.|
| 4 | Tune threshold trÃªn Linear SVM vá»›i class_weight=15 | Precision giáº£m nháº¹, Recall tÄƒng nháº¹, F2-score ~0.810 | Linear SVM tuyáº¿n tÃ­nh gáº§n nhÆ° Ä‘Ã£ khai thÃ¡c tá»‘i Ä‘a kháº£ nÄƒng biá»ƒu diá»…n | KhÃ´ng cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ F2, chá»‰ Ä‘iá»u chá»‰nh trade-off Precision/Recall | Dá»«ng Ä‘iá»u chá»‰nh threshold, thá»­ mÃ´ hÃ¬nh phi tuyáº¿n hoáº·c thÃªm anomaly detection | Hy vá»ng cÃ¡c phÆ°Æ¡ng phÃ¡p phi tuyáº¿n hoáº·c tÃ­n hiá»‡u anomaly sáº½ cáº£i thiá»‡n F2-score |
| 5 | Sá»­ dá»¥ng Random Forest vá»›i oversampling (SMOTE) | Cáº£i thiá»‡n recall so vá»›i Linear SVM mÃ  váº«n giá»¯ precision, xá»­ lÃ½ non-linear decision boundary | Linear SVM khÃ³ má»Ÿ rá»™ng hÆ¡n, RF cÃ³ kháº£ nÄƒng capture fraud náº±m sÃ¢u trong majority, oversampling giÃºp cÃ¢n báº±ng dá»¯ liá»‡u |---| DÃ¹ng oversampling Ä‘á»ƒ tÄƒng kháº£ nÄƒng nháº­n diá»‡n fraud mÃ  váº«n duy trÃ¬ precision; class_weight khÃ´ng trá»±c quan vá»›i RF | Hy vá»ng tÄƒng recall mÃ  khÃ´ng lÃ m giáº£m quÃ¡ nhiá»u precision, khÃ¡m phÃ¡ non-linear patterns, chuáº©n bá»‹ cho cÃ¡c bÆ°á»›c nÃ¢ng cao sau |
| 6 | SMOTE lÃ m precision giáº£m nháº¹ vÃ  recall chá»‰ tÄƒng Ã­t | Dá»¯ liá»‡u gian láº­n cÃ³ 2 nhÃ³m: easy fraud (cá»¥m rÃµ, dá»… phÃ¡t hiá»‡n), hard fraud (trÃ¹ng láº·p hoáº·c outlier, SMOTE táº¡o nhiá»…u) | Thay SMOTE báº±ng Borderline-SMOTE Ä‘á»ƒ chá»‰ sinh máº«u táº¡i vÃ¹ng biÃªn, cá»§ng cá»‘ ranh giá»›i yáº¿u, trÃ¡nh khuáº¿ch Ä‘áº¡i nhiá»…u | Recall â†—, Precision Ã­t giáº£m, váº«n khÃ³ phÃ¡t hiá»‡n hard fraud |
| 7 | Sá»­ dá»¥ng Borderline-SMOTE Ä‘á»ƒ resampling lá»›p minority | Má»¥c tiÃªu: cáº£i thiá»‡n recall mÃ  khÃ´ng lÃ m giáº£m precision quÃ¡ nhiá»u | Nháº­n xÃ©t: Precision cao vÃ  á»•n Ä‘á»‹nh hÆ¡n SMOTE (~0.805 vs ~0.707), recall tÄƒng nháº¹; cÃ¡c máº«u tá»•ng há»£p táº­p trung gáº§n biÃªn quyáº¿t Ä‘á»‹nh, trÃ¡nh nhiá»…u sÃ¢u vÃ o majority | Giáº£i thÃ­ch: Borderline-SMOTE táº­p trung vÃ o cÃ¡c Ä‘iá»ƒm gáº§n biÃªn, giáº£m False Positives, giá»¯ biÃªn quyáº¿t Ä‘á»‹nh gáº§n dá»¯ liá»‡u tháº­t | Quyáº¿t Ä‘á»‹nh: tiáº¿p tá»¥c tÃ¬m "sweet spot" cho sampling_strategy Ä‘á»ƒ tá»‘i Æ°u trade-off recall/precision | Ká»³ vá»ng: TÄƒng recall hÆ¡n ná»¯a mÃ  precision váº«n á»•n Ä‘á»‹nh, tÃ´n trá»ng imbalance thá»±c táº¿ |
|8 | Tune sampling_strategy | Thay Ä‘á»•i `sampling_strategy` tá»« 0.0015 Ä‘áº¿n 1.0 | F2 tá»‘t nháº¥t trong khoáº£ng 0.0015â€“0.025; precision giá»¯ á»Ÿ má»©c á»•n Ä‘á»‹nh, recall cáº£i thiá»‡n | `sampling_strategy` quÃ¡ cao cÃ³ thá»ƒ lÃ m lá»‡ch phÃ¢n phá»‘i dá»¯ liá»‡u thá»±c, giáº£m precision; quÃ¡ tháº¥p thÃ¬ recall khÃ´ng cáº£i thiá»‡n | Lá»±a chá»n sampling_strategy phÃ¹ há»£p giÃºp cÃ¢n báº±ng precision vÃ  recall; Borderline-SMOTE cá»§ng cá»‘ biÃªn yáº¿u mÃ  khÃ´ng khuáº¿ch Ä‘áº¡i nhiá»…u | Chá»n sampling_strategy ~0.0015â€“0.025 cho mÃ´ hÃ¬nh cuá»‘i | Precision á»•n Ä‘á»‹nh, recall cáº£i thiá»‡n, F2 tá»‘i Ä‘a, mÃ´ hÃ¬nh trÃ¡nh over-generalize dá»¯ liá»‡u tá»•ng há»£p |


# NOTES

## ğŸ‘‰ Directions:

- `TD` = top â†’ down
- `LR` = left â†’ right
- `BT` = bottom â†’ top

## ğŸ¤¨ Node shapes:

- `A[box]`
- `A(rounded)`
- `A((circle))`
- `A{diamond}`

